---
title: "Parallel Dithering: Is a speedup reachable ?"
author: |
    | Quentin Guilloteau
    | ENSIMAG & MoSIG DI
classoption: twocolumn
header-includes:
    - \usepackage{graphicx}
    - \usepackage{tikz}
    - \usetikzlibrary{decorations.pathreplacing,angles,quotes}
output:
    pdf_document:
        keep_tex: true
        number_sections: true
        fig_caption: yes
    html_document:
        keep_tex: true
        number_sections: true
abstract: "From palette reduction in GIF images to printing, dithering techniques are widely used. With the increasing size of the images today, due to better photographic hardware, we can wonder if we can gain in performance by processing an image in parallel. In this paper, we will implement a MPI algorithm to apply the Floyd-Steinberg dithering in parallel. We will then focus on performance and look for optimal values of parameters."
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

## Dithering

The action of dithering is used in image processing to reduce the number of colors used in an image.
One example is for printers that have only two values: either with ink or without.

The error diffusion in the dithering process consists in spreading to neighbouring pixels the quantification error due to the restriction of a pixel to a reduced palette.
This technique reduces phenomena such as banding (i.e. inaccurate color presentation) but introduces some noise.

In this paper, we will focus on the palette reduction of a grey scale image (256 values) to a black and white image (2 values: 0 and 255).

Figure \ref{fig:grey_scale} represents a grey scale image, and figure \ref{fig:dither} is its dither image.

\begin{figure}[h]
    \center
    \includegraphics[width=170px]{Images/charlie.png}
    \caption{Grey Scale Image}
    \label{fig:grey_scale}
\end{figure}

\begin{figure}[h]
    \center
    \includegraphics[width=170px]{Images/charlie_d.png}
    \caption{Dithered Image}
    \label{fig:dither}
\end{figure}

We can see on figure \ref{fig:dither} the dots composing the image.
Even with only two pixel values, the contrast of the different parts of the image is repescted.

## Floyd-Steinberg Dithering

There are many different possible ditherings.
They all use the same principle, only some numerical constants change.
In this paper, we will only focus on the __Floyd-Steinberg Dithering__.
It uses the error diffusion pattern depicted in figure \ref{fig:propagation}.

\begin{figure}
\center
\begin{tikzpicture}
    \draw (0,0) grid (3,2);
    \draw [->] (1.5,1.5) -- (2.25,1.5);
    \draw [->] (1.5,1.5) -- (2.25,0.75);
    \draw [->] (1.5,1.5) -- (1.5,0.75);
    \draw [->] (1.5,1.5) -- (0.75,0.75);
    \draw (2.5, 1.5) node {$\frac{7}{16}$};
    \draw (2.5, 0.5) node {$\frac{1}{16}$};
    \draw (1.5, 0.5) node {$\frac{5}{16}$};
    \draw (0.5, 0.5) node {$\frac{3}{16}$};
\end{tikzpicture}
\caption{Error Diffusion for the Floyd-Steinberg Dithering}
\label{fig:propagation}
\end{figure}

The dithering works as follows:

1. We assign a new value to the current pixel

2. We compute the error of this pixel as the difference between the new value and the old value

3. [Error Diffusion] We add a fraction of this error to the neighbouring pixels according to figure \ref{fig:propagation}


For example, if the error for the current pixel is 42, we will add $\frac{7}{16}\times 42$ to the value of the pixels on its right.

Figure \ref{fig:local_deps} shows another way to look at the problem, by considering the dependencies for a single pixel.

\begin{figure}
\center
\begin{tikzpicture}
    \draw (0,0) grid (3,2);
    \draw [->] (1.5,1.25) -- (1.5,0.75);
    \draw [->] (2.25,1.25) -- (1.75,0.75);
    \draw [->] (0.75,1.25) -- (1.25,0.75);
    \draw [->] (0.75,0.5) -- (1.25,0.5);
    \draw (2.5, 1.5) node {$\frac{3}{16}$};
    \draw (0.5, 1.5) node {$\frac{1}{16}$};
    \draw (1.5, 1.5) node {$\frac{5}{16}$};
    \draw (0.5, 0.5) node {$\frac{7}{16}$};
\end{tikzpicture}
\caption{Local Dependencies of the Floyd-Steinberg Dithering}
\label{fig:local_deps}
\end{figure}

## Pseudo-Code

We can write the pseudo code of the Floyd-Steinberg Dithering:

```C
for (y = 0; y < rows; y++) {
  for (x = 0; x < cols; x++) {
    // Computation of the error
    int old_value = pixels[y * cols + x];
    int new_value = (current_value < 127) ?
                    0 : 255;
    int error = old_value - new_value;
    pixels[y * cols + x] = new_value;

    // Error Propagation
    pixels[(y + 0) * cols + (x + 1)]
        += error * 7 / 16;
    pixels[(y + 1) * cols + (x + 1)]
        += error * 1 / 16;
    pixels[(y + 1) * cols + (x + 0)]
        += error * 5 / 16;
    pixels[(y + 1) * cols + (x - 1)]
        += error * 3 / 16;

  }
}
```

As we can see, this algorithm is _highly sequential_.
We have to start from the top left of the image and work ourselves to the right until we reach the end of the line.
Then we start again from the next line.


# Experimental Setup

Let us present the experimental setup used for every experiment presented on this paper.

## Experimental Design

All the experiments presented in this paper have 2 associated R scripts:

\begin{itemize}
    \item A script generating the design of the experiment.
    \item A script reading the design of the experiment and running it.
\end{itemize}

The first one will generate a CSV file composed of all the configurations to benchmark during the experiment.
The second one will read the first one and then run the correct MPI commands to run the experiment.

## Hardware

For all the experiements, we used the Grid5000 __dahu__ cluster located in Grenoble.

The hardware on this cluster is:

* CPU: 2 x Intel Xeon Gold 6130

* Cores: 16 cores/CPU

* Memory: 192 GiB

* Storage: 240 GB SSD + 480 GB SSD + 4.0 TB HDD

* Network: 10 Gbps + 100 Gbps Omni-Path

# Important Notions

We will here give some notions and notations that we will use for the rest of this paper.

* $w$: processing time of a single pixel

* $H$: height of the image

* $W$: width of the image

* $p$: number of processes

* $T(H, W, p)$: execution time of the algorithm depending on the image and the number of processors

* $S(H, W, p) = \frac{t_{seq}}{t_{par}}$: speedup of the algorithm for an image of size $H\times W$ with $p$ processors (the greater the better)

* $Eff = \frac{S(H, W, p)}{p}$: efficiency (the greater the better)

# Parallel Dithering

The main idea of the parallel dithering, is that the progression looks more like a triangle than a rectangle:


\begin{figure}
    \center
    \begin{tikzpicture}
        \draw (0,0) grid (5,4);
        \draw (0.5, 3.5) node {1};
        \draw [gray] (1.5, 3.5) node {2};
        \draw [red] (0.5, 2.5) node {3};
        \draw [red] (2.5, 3.5) node {3};

        \draw [orange] (3.5, 3.5) node {4};
        \draw [orange] (1.5, 2.5) node {4};

        \draw [blue] (0.5, 1.5) node {5};
        \draw [blue] (2.5, 2.5) node {5};
        \draw [blue] (4.5, 3.5) node {5};
    \end{tikzpicture}

\caption{Potential Parallel Execution}
\label{fig:ppe}
\end{figure}

Figure \ref{fig:ppe}, shows that there are indeed some possible parallelism in the dithering process.
The numbers correspond to the order of the execution.
When some pixels have the same number, it means that they can be processed in parallel.

We also see that each line needs to be 2 pixels ahead of the line below due to the error diffusion pattern of the dithering algorithm (see figure \ref{fig:propagation}).

## Alternate Processes: Presentation

The first idea to process the image in parallel is to alternate processes and giving them one line at the time to work with.

\begin{figure}
    \center
    \begin{tikzpicture}
        \draw (0,0) grid (5,4);
        \draw[decoration={brace,mirror,raise=0pt},decorate](5.2,0) -- node[right=3pt] {$P_1$} (5.2, 1);
        \draw[decoration={brace,mirror,raise=0pt},decorate](5.2,2) -- node[right=3pt] {$P_1$} (5.2, 3);

        \draw[decoration={brace,raise=0pt},decorate](-0.2,1) -- node[left=3pt] {$P_0$} (-0.2, 2);
        \draw[decoration={brace,raise=0pt},decorate](-0.2,3) -- node[left=3pt] {$P_0$} (-0.2, 4);
    \end{tikzpicture}

\caption{Data Distribution per Process (with 2 processes)}
\label{fig:alternate_processes}
\end{figure}

Figure \ref{fig:alternate_processes} gives an example of the distribution of data between 2 processes.

Process 0 will start working on the first pixel of its line.
As we saw in figure \ref{fig:ppe}, a process must be done processing pixel $n$ of its line for the next process to be able to process the pixel $n - 2$ of its own line.
So, we have to make sure to respect this requirement.

## Implemenation Details

### Representing one Pixel

One decision made to simplify the code was to encode pixel values on a ``int16_t`` integer.

Of course, pixels in a grey scale image only go from 0 to 255, only requiring 8 bits.

However, as we will need to add or substract error values to the value of a pixel, being able to have negative values was crucial.

### Distributing the lines to the processes

As one process has non adjacent lines, we have to define our own ``MPI_Vector_Type`` to properly send the correct lines to each process.

As we want process $P_{i}$ to have $\frac{H}{p}$ lines with $p - 1$ lines between each line and stating with the $i$th line.

```{C}
// Definition of the custom type
MPI_Type_vector(h / world_size,
                w, world_size * w,
                MPI_INT16_T, &PixelLine);
MPI_Type_commit(&PixelLine);
```

Unfortunatly, it is not possible to simply use the ``MPI_Scatter`` function to send the pixels to the processes.
Indeed, it will start the next ``PixelLine`` at the end of the previous one, however, we want it to start at the same position that the previous one with an offset of ``w``.

So we decided to simply call the ``MPI_Send`` function manually to scatter the lines among the processes.

#### Processing a line

Apart for the first line of the first process, every process has to receive the error from the above process to be able to process the pixels of its current line.

```{C}
// Call to recv the error from above
MPI_Recv(&error_from_top, 1, MPI_INT16_T,
    (my_rank + world_size - 1) % world_size,
    0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
```

Once the error from the process above has been received, we need to update the value of the current pixel.

```{C}
// Updating the local value
local_pixels[i + w * line_index]
        += error_from_top;
```

At this point, we can compute the new value for this pixel and its error to propagate.

```{C}
// Processing the current pixel
int16_t current_value =
    local_pixels[i + w * line_index];
int16_t new_value = (current_value < 127) ?
                    0 : 255;
local_pixels[i + w * line_index] = new_value;
int16_t error = current_value - new_value;
```

### Propagating the error to the process below

As figure \ref{fig:propagation} shows, once its value updated, one pixel has to send its error to (at most) 3 pixels to the line below.
However, in order for the first error of the line to be send to the process below, we need to wait for the second pixel to be done processing as we want to send the error only once.

We decided to use a circular buffer of size 3 to manage this issue.

This buffer will store the cumulated errors to send to the process below until they are ready to be sent.
We need a size of 3 because a pixel propagates its error to (at most) 3 pixels on the line below.

\begin{figure}
    \center
    \begin{tikzpicture}
        % Drawing the lines and buffers
        \draw (0,0) grid (4,1);
        \draw (0,2) grid (3,3);
        \draw (0,4) grid (4,5);

        % Drawing the lines
        \draw [->, dashed] (0.5,4.5) -- (0.5,2.75);
        \draw [->, dashed] (0.5,4.5) -- (1.25,2.75);
        \draw [black] (0.5, 4.75) node {1};
        \draw (0.5, 4.75) circle (0.15);

        \draw [->, dashed] (1.5,4.5) -- (0.75,2.75);
        \draw [->, dashed] (1.5,4.5) -- (1.5,2.75);
        \draw [->, dashed] (1.5,4.5) -- (2.25,2.75);
        \draw [black] (1.5, 4.75) node {2};
        \draw (1.5, 4.75) circle (0.15);

        \draw [->] (0.5,2.5) -- node {send} (0.5,0.5);
        \draw [black] (-0.1, 1.47) node {3};
        \draw (-0.1, 1.47) circle (0.15);

        % Legend
        \draw (-1, 4.5) node {line $i$};
        \draw (-1, 2.5) node {Buffer};
        \draw (-1, 0.5) node {line $i + 1$};

       \draw[decoration={brace,mirror,raise=5pt},decorate](-1.7,5) -- node[left=6pt] {$P_{k}$} (-1.7,2);
       \draw[decoration={brace,mirror,raise=5pt},decorate](-1.7,1) -- node[left=6pt] {$P_{k + 1}$} (-1.7,0);


    \end{tikzpicture}

\caption{Use of the cicular buffer}
\label{fig:circular_buffer}
\end{figure}

Figure \ref{fig:circular_buffer} resumes the mechanism used with the buffer.

\begin{enumerate}
    \item The first pixel of line $i$ is processed on process $P_{k}$. We add the proportions of the error to the corresponding cells of the buffer. In this example, there are only 2 cells to update as we are on the far left on the image (see figure \ref{fig:ptopagation})
    \item The second pixel of line $i$ is processed on process $P_{k}$. We add the propotions of the error to the corresponding cells of the buffer.
    \item The first cell of the buffer is ready to be send to process $P_{k+1}$ (no more dependencies). It contains the cumulated error for the first pixel of line $i+1$.
    \item Once sent, we set the value of the sent cell back to 0.
\end{enumerate}

As the buffer is circular, the first cell will be used to store the error for the right dependency of the $3^{rd}$ pixel.




## Performance Analysis
\label{sec:alternate}

Let $p$ be the number of processors.
Let us consider an image of size $H\times W$.
Let $L$ be the latency of the network and $B$ its bandwidth.
Let $w$ be the processing time of a pixel.

Each processor has $\frac{H\times W}{p}$ pixels to process.

The global time spent "busy waiting" is $2(H-1)w$ (because of the 2 pixels spacing between processes) and we have to wait for the last process to finish.

We thus have:

\begin{equation}
T(H, W, p) = \frac{HW}{p} \left( w + L + \frac{1}{B}\right) + 2(H-1)w
\end{equation}

The sequential time is: $w H W$.

We can thus compute the speedup:

$$
\displaystyle S(H, W, p) = \frac{wHW}{\frac{HW}{p} \left( w + L + \frac{1}{B}\right) + 2(H-1)w}
$$

The limit speedup is thus:

\begin{equation}
\displaystyle \lim_{(H, W) \rightarrow (\infty, \infty)} S(H, W, p) = \frac{1}{\frac{1}{p} + \frac{L}{wp} + \frac{1}{wpB}}
\end{equation}

The efficiency of this algorithm is:

\begin{equation}
\label{eq:eff1}
\displaystyle Eff  = \lim_{(H, W) \rightarrow (\infty, \infty)} \frac{S(H, W, p)}{p} = \frac{1}{1 + \frac{L}{w} + \frac{1}{B \times w}}
\end{equation}

The efficiency of this algorithm (equation \ref{eq:eff1}) is less than one.
It thus means that it is not very efficient.

# Reducing the Granularity

## Presentation

Sending the error every time a process process a pixel introduce too much loss due to the latency of the network.
We will try to reduce the granularity of the algorithm by grouping pixels per block.
We will also send the errors per block.
We call $k$ the number of pixels in a block.
Figure \ref{fig:blocks} summarise the execution of a line of pixels using blocks.

\begin{figure}
    \center
    \begin{tikzpicture}
        \draw [black] (-1, 0.5) node {Step 1};
        \draw [gray] (0,0) grid (6,1);
        \draw [black,thick,dashed] (0,-0.2) rectangle (2, 1.2);

        \draw [black] (-1, -1.5) node {Step 2};
        \draw [gray] (0,-2) grid (6,-1);
        \draw [black,thick,dashed] (2,-2.2) rectangle (4, -0.8);

        \draw[decoration={brace,raise=0pt},decorate](0,1.3) -- (2, 1.3);
        \draw [black] (1, 1.7) node {processing};

        \draw[decoration={brace,raise=0pt},decorate](2,1.3) -- (6, 1.3);
        \draw [black] (4, 1.7) node {to be processed};



        \draw[decoration={brace,mirror,raise=0pt},decorate](0,-2.3) -- (2, -2.3);
        \draw [black] (1, -2.7) node {processed};

        \draw[decoration={brace,mirror,raise=0pt},decorate](2,-2.3) -- (4, -2.3);
        \draw [black] (3, -2.7) node {processing};

        \draw[decoration={brace,mirror,raise=0pt},decorate](4,-2.3) -- (6, -2.3);
        \draw [black] (5, -3) node {to be processed};

        \draw [black, ->] (1, -0.5) -- (3, -0.5);
    \end{tikzpicture}

\caption{Execution per block with $k = 2$}
\label{fig:blocks}
\end{figure}

## Performance Analysis

We note $k$ the size of a block.
So a block contains $k$ pixels.

\begin{equation}
T(H, W, p) = \frac{HW}{p \times k} \left( w \times k + L + \frac{k}{B}\right) + 2k(H - 1)w
\end{equation}

We compute next the speedup of this new version:

$$
\displaystyle S(H, W, p) = \frac{wHW}{\frac{n^2}{p\times k} \left( w \times k + L + \frac{k}{B}\right) + 2k(H-1)w}
$$

The limit speedup is thus:

\begin{equation}
\displaystyle \lim_{(H, W) \rightarrow (\infty, \infty)} S(H, W, p) = \frac{1}{\frac{1}{p} + \frac{L}{wpk} +\frac{1}{wpB}}
\end{equation}

The efficiency of this algorithm is:

\begin{equation}
\label{eq:eff2}
\displaystyle Eff = \lim_{(H, W) \rightarrow (\infty, \infty)} \frac{S(H, W, p)}{p} = \frac{1}{1 + \frac{L}{wk} + \frac{1}{Bw}}
\end{equation}

We see that we improve the efficiency of the algorithm by limiting the use of the network and reducing the global cost of the latency.
So, the higher $k$, the less we will pay the cost of the latency.

## Upper bound for $k$

We want $k$ to be the higher possible, but if we increase $k$, we will at some point have some busy waiting time.

Let us find the upper bound for $k$ that does not generate busy waiting time.

### Theoretical Value

Let $W$ be the width of the image and $p$ be the number of processes.

In order to not have any idle time by the processes, we would like the process $P_{p-1}$ to have at least finished processing its first 2 blocks of its line when process $P_{0}$ is done processing its line.

Otherwise, process $P_{0}$ would have to wait for process $P_{p-1}$ to send the error of the first block, thus creating some busy-waiting time.

Let $k_{hi}$ be the lower bound of $k$ such that there is no busy waiting by the processes.

There are $\displaystyle \frac{W}{k}$ blocks to process on one line.

Once the first line will be done by process $P_{0}$, process $P_{p-1}$ would have processed $\frac{W}{k} - 2\times (p - 1)$.

We want the last process to have processed at least 2 blocks (so it can send the error of the first block to process $P_{0}$).

Thus,

\begin{equation}
\frac{W}{k} - 2\times (p - 1) \geq 2 \implies k \leq \frac{W}{2 \times p} = k_{hi}
\end{equation}

### Experiment

We took an example with an image of width 8192 pixels on 16 processors.
We doubled the block size starting from 2 pixels up to the total width of the image.

We can compute the upper bound for $k$:

\begin{equation}
k_{hi} = \frac{W}{2p} = \frac{8192}{2 \times 16} = 256
\end{equation}

```{r, echo=FALSE, fig.cap="\\label{fig:opti_k}Speedup depending on the block size ($k$)"}
df <- read.csv("experiments/data/output_upper_bound_k.csv", header = TRUE, sep = " ")

df$speedup <- df$seq_time / df$par_time

df <- df %>% group_by(k) %>% summarise(mean = mean(speedup), sd = sd(speedup))

df$disp <- df$sd * 100 / df$mean

df$confidence_inf <- df$mean - 2 * df$sd
df$confidence_sup <- df$mean + 2 * df$sd

labels <- df$k
labels[labels == 256] <- "k_hi"

ggplot(data = df, aes(x = k, y = mean)) +
    theme_bw() +
    geom_errorbar(aes(ymin = confidence_inf, ymax = confidence_sup), width = 0.2) +
    geom_point() +
    geom_vline(xintercept = 256, color = "blue") +
    scale_x_continuous(trans = 'log2', breaks = df$k, labels = labels) +
    scale_y_continuous(limits = c(0, 2)) +
    xlab("block size") +
    ylab("Speedup") +
    ggtitle("Speedup depending on the block size")
```

In figure \ref{fig:opti_k} we show that the speedup is indeed maximal for $k = k_{hi}$.

### Remarks

We can also see a small dip in performance for $k = 16$.
We suspect that it must be linked to MPI having different ways to send the data depending on the size of the message compared to a threshold.

# Limiting the Impact of the Bandwidth

## Presentation

For the moment, we only managed to reduce the cost of the latency of the network.
In order to reduce the impact of the bandwith, we must send less messages through the network.
In the previous section, we increased the size of the messages by sending pixels per block.
In this section, we will create blocks of lines.
Each process will have several blocks of lines.
Each block of line will contain $r$ __consecutive__ lines of pixels.
Only the top and bottom lines of the block will require communications.
The remaining pixels will be processed sequentially.

We cannot however afford to process the pixels in a block of lines, sequentially line by line from left to right.
Indeed, this would result in too much time "busy waiting" for the processes.
We thus decided to process the pixels in the block of lines in a zig-zag (or serpentine) way, as depicted in figure \ref{fig:zigzag}.


\begin{figure}
    \center
    \begin{tikzpicture}
        \draw [gray] (0,0) grid (6,3);
        \draw[decoration={brace,raise=0pt},decorate](-0.2,0) -- node[left=3pt] {$r$} (-0.2, 3);
        \draw [->] (0.5,2.5) -- (1.5, 2.5) -- (0.5,1.5) -- (2.5,2.5) -- (1.5,1.5) -- (0.5,0.5) -- (3.5,2.5) -- (2.5,1.5) -- (1.5,0.5);

        \draw [gray, dashed, ->] (0.5, 3.7) -- (0.5, 3.2);
        \draw (0.5, 4) node {recv};

        \draw [gray, dashed, ->] (1.5, 3.7) -- (1.5, 3.2);
        \draw (1.5, 4) node {recv};

        \draw [gray, dashed, ->] (2.5, 3.7) -- (2.5, 3.2);
        \draw (2.5, 4) node {recv};

        \draw [gray, dashed, ->] (3.5, 3.7) -- (3.5, 3.2);
        \draw (3.5, 4) node {recv};


        \draw [gray, dashed, ->] (0.5, -0.5) -- (0.5, -1);
        \draw (0.5, -0.2) node {send};

        \draw [gray, dashed, ->] (1.5, -0.5) -- (1.5, -1);
        \draw (1.5, -0.2) node {send};

    \end{tikzpicture}

\caption{Zig-Zag processing on a block of $r = 3$ lines}
\label{fig:zigzag}
\end{figure}

## Performance Anlysis

We pretty much have the same logic than in section \ref{sec:alternate}, with blocks instead of pixels.

The waiting time is:

\begin{equation}
Wait = wk\left(\frac{H}{r} - 1\right)\frac{r(r-1)}{2} = wk\frac{(H-r)(r-1)}{2}
\end{equation}

\begin{equation}\label{eq:t_r}
T(H, W, p) = \frac{HW}{krp} \left( wk + L + \frac{k}{B}\right) + wk\frac{(H-r)(r-1)}{2}
\end{equation}

We compute next the speedup of this new version:

$$
\displaystyle S(H, W, p) = \frac{wHW}{\frac{HW}{krp} \left( wk + L + \frac{k}{B}\right) + wk\frac{(H-r)(r-1)}{2}}
$$

The limit speedup is thus:

\begin{equation}
\displaystyle \lim_{(H, W) \rightarrow (\infty, \infty)} S(H, W, p) = \frac{1}{\frac{1}{pr} + \frac{L}{pkrw} + \frac{1}{pwrB}}
\end{equation}

The efficiency of this algorithm is:

\begin{equation}
\label{eq:eff2}
\displaystyle Eff  = \lim_{(H, W) \rightarrow (\infty, \infty)} \frac{S(H, W, p)}{p} = \frac{1}{\frac{1}{r} + \frac{L}{wkr} + \frac{1}{Brw}}
\end{equation}

We see that we improve the efficiency of the algorithm by limiting the use of the network and reducing the global cost of the bandwidth.
The highest $r$ is, the better the speedup will be.

## Upper bound for $r$

As for $k$, increasing $r$ too much will produce some busy waiting time.
Let us find the upper bound for $r$ that does not produce busy waiting time.

### Theoretical Value

In order to process the $i^{th}$ block of pixel of the last line of the block of line, we need to process the $(i + 1)^{th}$ block of the previous line of the block.

We can then compute the number of block to process first to be able to process the $i^{th}$ block of the last line:

\begin{equation}
\displaystyle \sum_{j=0}^{r-1} i + j = r\times i + \frac{(r-1)r}{2}
\end{equation}

So, to send the first error to the process below, we need to process the first 2 blocks of the last line (i.e. $i = 2$).
Thus, we need to process the total of $\frac{r(r + 3)}{2}$ blocks of pixels.

The working time is then:

\begin{equation}
Work = wk\frac{r(r+3)}{2}
\end{equation}

We don't want to have processes being busy waiting between when they finish processing their previous block of lines and when they start their next block of lines.

For processes other than the first one, there are actually unavoidable waiting times.
Indeed, for example, to receive the second error, a process has to wait for the process above to send it.
However, there is not enough work to do yet to be busy until the error is sent.


The waiting time for such a process is:

\begin{equation}
\displaystyle Wait = wk\sum_{i = 1}^{r} (r - i) = wk\frac{r(r-1)}{2}
\end{equation}

Thus, for processes that are not the first process, the time to send the first error is:
\begin{equation}
\displaystyle Work + Wait = wk\frac{r(r + 3)}{2} + wk\frac{r(r-1)}{2} = wkr(r + 1)
\end{equation}

Thus, the total time to get the first error in the second block of line of the first process is:

\begin{equation}
wk\frac{r(r+3)}{2} + wk(p - 1)r(r+1) = wkr\left(r\left(p - \frac{1}{2}\right) + \left(p + \frac{1}{2}\right)\right)
\end{equation}

We want the first process to finish the first block of lines after the first error for its second block of lines is sent:

\begin{equation}
r\left(r\left(p - \frac{1}{2}\right) + \left(p + \frac{1}{2}\right)\right) \leq \frac{W}{k}r
\end{equation}

Thus, the upper bound for $r$ is:

\begin{equation}\label{eq:up_r}
r \leq \frac{\frac{W}{k} - \left(p + \frac{1}{2}\right)}{p - \frac{1}{2}} = r_{hi}
\end{equation}

We can also express the value of $k$ given $r$:
\begin{equation}\label{eq:k_in_function_of_r}
k = \frac{W}{r\left(p - \frac{1}{2}\right) + \left(p + \frac{1}{2}\right)}
\end{equation}

### Experiment

We can now make an experiement.

We fixed $H$, $W$ and $p$.
We took a range of values for $r$ and took the $k$ value associated with this $r$ (see equation \ref{eq:k_in_function_of_r}).
We plot the speedup for each configuration.

```{r, echo=FALSE, fig.cap="\\label{fig:opti_r}Speedup depending on the block size ($r$)"}
df <- read.csv("experiments/data/output_upper_bound_r_new.csv", header = TRUE, sep = " ")
df_k <- read.csv("experiments/data/output_upper_bound_r.csv", header = TRUE, sep = " ")

df$speedup <- df$seq_time / df$par_time
df_k$speedup <- df_k$seq_time / df_k$par_time


rmax <- (df$w/df$k - (df$p + 0.5)) / (df$p - 0.5)
rmax_k <- (df_k$w/df_k$k - (df_k$p + 0.5)) / (df_k$p - 0.5)
df <- df %>% group_by(r) %>% summarise(mean = mean(speedup), sd = sd(speedup))
df_k <- df_k %>% group_by(r) %>% summarise(mean = mean(speedup), sd = sd(speedup))

df$disp <- df$sd * 100 / df$mean

df$confidence_inf <- df$mean - 2 * df$sd
df$confidence_sup <- df$mean + 2 * df$sd

df_k$confidence_inf <- df_k$mean - 2 * df_k$sd
df_k$confidence_sup <- df_k$mean + 2 * df_k$sd

ggplot() +
    theme_bw() +
    geom_point(data = df, aes(x = r, y = mean), color = "black") +
    geom_errorbar(data = df, aes(x = r, ymin = confidence_inf, ymax = confidence_sup), width = 0.2) +
    geom_vline(xintercept = rmax, color = "blue") +
    # geom_point(data = df_k, aes(x = r, y = mean), color = "green") +
    # geom_errorbar(data = df_k, aes(x = r, ymin = confidence_inf, ymax = confidence_sup), width = 0.2) +
    # geom_vline(xintercept = rmax_k, color = "blue") +
    scale_x_continuous(trans = 'log2', breaks = df$r) +
    scale_y_continuous(limits = c(0, 3)) +
    xlab("block size") +
    ylab("Speedup") +
    ggtitle("Speedup depending on the block size")
```

We can see the results of the experiment in fugure \ref{fig:opti_r}.

We see that for $r = r_{hi}$, we optain the highest speedup.

### Remarks

If we plug $k = k_{hi}$ in the value of the upper bound for $r$, we get $r \leq 1$.
Which makes sense as this is an optimal value of $k$ for blocks of one line.

# Optimal block sizes

## Assumptions

In equation \ref{eq:up_r}, we found a relation linking the parameters of our problem: $r$ and $k$.

We can thus easily get the optimal value of one given the other.
The question now is to get the best couple $(r, k)$.

From \ref{eq:t_r}, we have:

\begin{equation*}
T = \frac{HW}{prk}\left(L + \frac{k}{B} + wk\right) + \frac{(H - r)(r - 1)}{2}wk
\end{equation*}

Let us focus on the "busy waiting" time and try to minimize it.

$$
Wait = \frac{(H - r)(r - 1)}{2}k
$$

We can plug the expression of $k$ found in equation \ref{eq:k_in_function_of_r} and derive with respect to $r$:

$$
Wait = \frac{(H - r)(r - 1)W}{2\left(r\left(p - \frac{1}{2}\right) + p + \frac{1}{2}\right)}
$$

Let us derive with respect to $r$:

\begin{equation}
\frac{(H+1-2r)(r(p-\frac{1}{2}) + p + \frac{1}{2}) - (H-r)(r-1)(p-\frac{1}{2})}{(r(p-\frac{1}{2})+p+\frac{1}{2})^2}
\end{equation}

We are looking at when the upper part equals 0.

After some manipulations, we obtain:

\begin{equation}
r^2(2 - P) + r((H+3)P - (H + 1)) - (2H+1)P = 0
\end{equation}

with $\displaystyle P = \frac{p + \frac{1}{2}}{p - \frac{1}{2}}$

We can assume that $P=1$, which is reasonable for values of $p > 10$.

We thus get the following equation:

\begin{equation}
r^2 + 2r - (2H+1) = 0
\end{equation}

The positive solution, which is the $r$ minimizing the waiting time, is:

\begin{equation}
r_{+} = -1+\sqrt{2(H+1)}
\end{equation}

For large values of $H$ we can simply take $r \simeq \sqrt{2H}$

## Example

```{r, echo=FALSE}
H <- 2^13
W <- 2^13
p <- 16
```

Let us take an example with a square image of size $`r H`\times `r W`$ with `r p` processes.

```{r}
H <- 2^13
W <- 2^13
p <- 16

r <- sqrt(2 * H)
r
k <- W / (r * (p - 0.5) + (p + 0.5))
k
```

We have to take the $r$ the closest to this optimal value such that $H \equiv 0~ (mod~ r\times p)$.

In this particular case:

```{r, warning=FALSE}
r <- 2^(as.integer(log2(r)))
r
k <- W / (r * (p - 0.5) + (p + 0.5))
k
```
We also need $k$ to be a valid number (integer that divides $W$).


So, in this example, we would take $r = `r r`$ and $k = `r 2^(as.integer(log2(k)))`$

## Experiment

We can thus make an experiment in order to check if the theorical optimal value for $r$ is the one we found.

In this experiement, we fixed the size of the image and the number of processors.
We generated points for some possible values of $r$ and computed the optimal value of $k$ associated with this value of $r$ (see equation \ref{eq:k_in_function_of_r}).
We added to the dataset the optimal configuration.
We then mesured the speedup for each configuration and plotted the results in figure \ref{fig:opti}.

```{r, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:opti}Speedup depending on the block size ($r$)"}
df <- read.csv("experiments/data/output_r_opti.csv", header = TRUE, sep = " ")

df$speedup <- df$seq_time / df$par_time

opti_r <- function(h, w, p) {
    roots <- polyroot(z = c(h*w, 0, -h/2, 1))
    roots[1]
}
r_opti <- opti_r(df$h[1], df$w[1], df$p[1])

df <- df %>% group_by(r) %>% summarise(mean = mean(speedup), sd = sd(speedup))

df$confidence_inf <- df$mean - 2 * df$sd
df$confidence_sup <- df$mean + 2 * df$sd

ggplot() +
    theme_bw() +
    geom_point(data = df, aes(x = r, y = mean), color = "black") +
    geom_errorbar(data = df, aes(x = r, ymin = confidence_inf, ymax = confidence_sup), width = 0.2) +
    geom_vline(xintercept = as.integer(r_opti), color = "blue") +
    scale_x_continuous(trans = 'log2', breaks = df$r) +
    scale_y_continuous(limits = c(0, 4)) +
    xlab("block size") +
    ylab("Speedup") +
    ggtitle("Speedup depending on the block size")
```

We can see that the theorical optimal value of $r$ (in blue on figure \ref{fig:opti}) is not exactly the experiemental optimal value (around $r = 64$).

However, after $r = 64$, there seems to be a "plateau" where the speedup does not variate much.
Thus by keeping the therorical optimal $r$, we could still get some high performances.

## Summary
\label{sec:rules}

Given an image of size $H\times W$, and $p$ processors, we recommend taking:

* $\displaystyle r \simeq \sqrt{2H}$

* $\displaystyle k \simeq \frac{W}{p\sqrt{2H}}$

# Performances

In this experiment, we fix the image size and increase the number of processes.

The values of $r$ and $k$ are computed with respect to the rules given in \ref{sec:rules}.

```{r, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:perf}Speedup depending on te number of processors"}
df <- read.csv("experiments/data/output_final.csv", header = TRUE, sep = " ")

df$speedup <- df$seq_time / df$par_time

df <- df %>% group_by(p) %>% summarise(mean = mean(speedup), sd = sd(speedup))

df$confidence_inf <- df$mean - 2 * df$sd
df$confidence_sup <- df$mean + 2 * df$sd

lm_result <- lm(data = df, mean ~ log(p))

predictions <- data.frame("p" = seq(1, 128, 1))
predictions$prediction <- predict(lm_result, predictions)

ggplot() +
    theme_bw() +
    geom_point(data = df, aes(x = p, y = mean), color = "black") +
    geom_errorbar(data = df, aes(x = p, ymin = confidence_inf, ymax = confidence_sup), width = 0.2) +
    geom_smooth(method = loess, formula = y ~ x, data = predictions, aes(x = p, y = prediction)) + 
    scale_x_continuous(trans = 'log2', breaks = df$p) +
    scale_y_continuous(limits = c(0, 4)) +
    xlab("Number of processors") +
    ylab("Speedup") +
    ggtitle("Speedup depending on the number of processors")
```

We can do a linear regression for the speedup, and we find that:

\begin{equation}
S(p) \simeq \log_2 (\sqrt{p}) + 1
\end{equation}


# Conclusion

## To go further

### Powers of 2

In this paper, we decided to limit the implementation to a "simple" use.
Indeed, our implementation requires $H \equiv 0 \pmod k$ and $H \equiv 0~ (mod~ r\times p)$.
Those constraints are limiting.
This is why all the experiments are based on powers of 2.

But, by only using image with a size that is a power of 2, we limit ourselves to a very small region of the space.
We hope however that measuring on those points gave us enough information on the global space.

With more time, implementing a generic program to take any $k$ and any $r$ would allow us to be more precise in our experiments and analysis.

### Another Dithering Algorithm

There are several dithering algorithms.
We could also compare the impact of the error-diffusion on the performances.

For instance, the __Jarvis, Judice and Ninke Dithering__ has the error diffusion pattern depicted in figure \ref{fig:jarvis}.


\begin{figure}
\center
\begin{tikzpicture}
    \draw (0,0) grid (5,3);
    % \draw [->] (2.5,2.5) -- (2.25,1.5);
    % \draw [->] (2.5,2.5) -- (2.25,0.75);
    % \draw [->] (2.5,2.5) -- (1.5,0.75);
    % \draw [->] (2.5,2.5) -- (0.75,0.75);
    \draw (2.5, 2.5) node {$X$};
    \draw (3.5, 2.5) node {$\frac{7}{48}$};
    \draw (4.5, 2.5) node {$\frac{5}{48}$};
    \draw (4.5, 1.5) node {$\frac{3}{48}$};
    \draw (3.5, 1.5) node {$\frac{5}{48}$};
    \draw (2.5, 1.5) node {$\frac{7}{48}$};
    \draw (1.5, 1.5) node {$\frac{5}{48}$};
    \draw (0.5, 1.5) node {$\frac{3}{48}$};
    \draw (0.5, 0.5) node {$\frac{1}{48}$};
    \draw (1.5, 0.5) node {$\frac{3}{48}$};
    \draw (2.5, 0.5) node {$\frac{5}{48}$};
    \draw (3.5, 0.5) node {$\frac{3}{48}$};
    \draw (4.5, 0.5) node {$\frac{1}{48}$};
\end{tikzpicture}
\caption{Error Diffusion for the Jarvis, Judice and Ninke Dithering}
\label{fig:jarvis}
\end{figure}


### GPU and Shared Memory

It would also be interesting to develop versions of a parallel Floyd-Steinberg Dithering on a GPU with CUDA and on shared memory (with Rust and Rayon or with OpenMP) and look at the difference in performances.

## Performances

Concerning performances, we manage to reduce the execution time by:

* Working on blocks of pixels instead of single pixels: reduced the impact of the latency of the network

* Giving several consecutive lines to each process: reduced the impact of the network (latency + bandwith)

* Computing optimal values of $k$ and $r$: those values are computed to reduce waiting time
